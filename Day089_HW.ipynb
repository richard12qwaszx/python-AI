{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work\n",
    "1. 請自行定義一個 loss function, 為 0.3 * focal loss + 0.7 cross-entropy，訓練並比較結果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Richard\\anaconda3\\envs\\finlab\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Richard\\anaconda3\\envs\\finlab\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Richard\\anaconda3\\envs\\finlab\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Richard\\anaconda3\\envs\\finlab\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Richard\\anaconda3\\envs\\finlab\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Richard\\anaconda3\\envs\\finlab\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Richard\\anaconda3\\envs\\finlab\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Richard\\anaconda3\\envs\\finlab\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Richard\\anaconda3\\envs\\finlab\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Richard\\anaconda3\\envs\\finlab\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Richard\\anaconda3\\envs\\finlab\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Richard\\anaconda3\\envs\\finlab\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "\n",
    "# Disable GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 資料前處理\n",
    "def preproc_x(x, flatten=True):\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# Preproc the inputs\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# Preprc the outputs\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "\n",
    "\"\"\"\n",
    "建立神經網路，並加入 BN layer\n",
    "\"\"\"\n",
    "def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128]):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1))(input_layer)\n",
    "            x = BatchNormalization()(x)\n",
    "        else:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1))(x)\n",
    "            x = BatchNormalization()(x)\n",
    "    \n",
    "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 超參數設定\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 1024\n",
    "MOMENTUM = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "\"\"\"Code Here\n",
    "撰寫一個 loss function, 使其可以結合 focal loss 與 crossentropy loss\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# 撰寫自定義的 loss function: focal loss (https://blog.csdn.net/u014380165/article/details/77019084)\n",
    "\"\"\"\n",
    "def focal_loss(gamma=2., alpha=4.):\n",
    "    gamma = float(gamma)\n",
    "    alpha = float(alpha)\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        \"\"\"Focal loss for multi-classification\n",
    "        FL(p_t)=-alpha(1-p_t)^{gamma}ln(p_t)\n",
    "        \"\"\"\n",
    "        epsilon = 1e-8\n",
    "        y_true = tf.convert_to_tensor(y_true, tf.float32)\n",
    "        y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n",
    "\n",
    "        model_out = tf.add(y_pred, epsilon)\n",
    "        ce = tf.multiply(y_true, -tf.log(model_out))\n",
    "        weight = tf.multiply(y_true, tf.pow(tf.subtract(1., model_out), gamma))\n",
    "        fl = tf.multiply(alpha, tf.multiply(weight, ce))\n",
    "        reduced_fl = tf.reduce_max(fl, axis=1)\n",
    "        return tf.reduce_mean(reduced_fl)\n",
    "    return focal_loss_fixed\n",
    "\n",
    "ce_weights_list = [0., 0.3, 0.5, 0.7, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of exp: 0, ce_weight: 0.00\n",
      "WARNING:tensorflow:From C:\\Users\\Richard\\anaconda3\\envs\\finlab\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Richard\\anaconda3\\envs\\finlab\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Richard\\anaconda3\\envs\\finlab\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Richard\\anaconda3\\envs\\finlab\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\Richard\\anaconda3\\envs\\finlab\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Richard\\anaconda3\\envs\\finlab\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\Richard\\anaconda3\\envs\\finlab\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 5.9945 - acc: 0.3274 - val_loss: 6.3611 - val_acc: 0.3359\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 4.3636 - acc: 0.4418 - val_loss: 4.9433 - val_acc: 0.3872\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 3s 64us/step - loss: 3.9487 - acc: 0.4821 - val_loss: 4.3521 - val_acc: 0.4384\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 3.6943 - acc: 0.5069 - val_loss: 4.4358 - val_acc: 0.4229\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 3.4801 - acc: 0.5279 - val_loss: 4.0910 - val_acc: 0.4532\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 3.2886 - acc: 0.5474 - val_loss: 4.0254 - val_acc: 0.4633\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 3.1203 - acc: 0.5656 - val_loss: 3.9933 - val_acc: 0.4754\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 2.9723 - acc: 0.5818 - val_loss: 4.0301 - val_acc: 0.4617\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 2.8178 - acc: 0.5986 - val_loss: 3.9357 - val_acc: 0.4771\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 2.6813 - acc: 0.6131 - val_loss: 3.9690 - val_acc: 0.4791\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 2.5515 - acc: 0.6264 - val_loss: 3.9544 - val_acc: 0.4797\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 2.4252 - acc: 0.6413 - val_loss: 4.3576 - val_acc: 0.4401\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 2.3045 - acc: 0.6546 - val_loss: 3.9916 - val_acc: 0.4767\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 2.1658 - acc: 0.6709 - val_loss: 3.9657 - val_acc: 0.4858\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 2.0401 - acc: 0.6842 - val_loss: 4.2304 - val_acc: 0.4635\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 1.9274 - acc: 0.6999 - val_loss: 4.1329 - val_acc: 0.4709\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 1.8110 - acc: 0.7153 - val_loss: 4.1852 - val_acc: 0.4721\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 1.7068 - acc: 0.7291 - val_loss: 4.1459 - val_acc: 0.4814\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 1.5918 - acc: 0.7434 - val_loss: 4.2448 - val_acc: 0.4802\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 1.4890 - acc: 0.7576 - val_loss: 4.3117 - val_acc: 0.4783\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 1.3856 - acc: 0.7735 - val_loss: 4.3579 - val_acc: 0.4826\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 1.3020 - acc: 0.7829 - val_loss: 4.3917 - val_acc: 0.4801\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 1.2045 - acc: 0.7980 - val_loss: 4.4701 - val_acc: 0.4806\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 1.1020 - acc: 0.8132 - val_loss: 4.5311 - val_acc: 0.4852\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 1.0210 - acc: 0.8251 - val_loss: 4.5907 - val_acc: 0.4758\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 0.9410 - acc: 0.8384 - val_loss: 4.7267 - val_acc: 0.4661\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 0.8657 - acc: 0.8500 - val_loss: 4.7689 - val_acc: 0.4768\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 0.7860 - acc: 0.8622 - val_loss: 4.8744 - val_acc: 0.4739\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 0.7150 - acc: 0.8755 - val_loss: 5.0062 - val_acc: 0.4718 - loss:\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 0.6530 - acc: 0.8859 - val_loss: 4.9897 - val_acc: 0.4679\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 3s 64us/step - loss: 0.5963 - acc: 0.8943 - val_loss: 5.0526 - val_acc: 0.4769\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 0.5377 - acc: 0.9056 - val_loss: 5.1824 - val_acc: 0.4665\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 3s 64us/step - loss: 0.4886 - acc: 0.9161 - val_loss: 5.3072 - val_acc: 0.4721\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 3s 64us/step - loss: 0.4349 - acc: 0.9255 - val_loss: 5.3526 - val_acc: 0.4680\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 3s 64us/step - loss: 0.4034 - acc: 0.9298 - val_loss: 5.5098 - val_acc: 0.4768\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 3s 64us/step - loss: 0.3636 - acc: 0.9387 - val_loss: 5.5514 - val_acc: 0.4631\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 0.3212 - acc: 0.9478 - val_loss: 5.5988 - val_acc: 0.4702\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 0.2826 - acc: 0.9557 - val_loss: 5.6588 - val_acc: 0.4724\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 3s 64us/step - loss: 0.2610 - acc: 0.9601 - val_loss: 5.7066 - val_acc: 0.4629\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 3s 64us/step - loss: 0.2392 - acc: 0.9629 - val_loss: 5.7266 - val_acc: 0.4745\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 3s 64us/step - loss: 0.2074 - acc: 0.9709 - val_loss: 5.7895 - val_acc: 0.4764\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 0.1888 - acc: 0.9729 - val_loss: 5.8929 - val_acc: 0.4678\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 0.1739 - acc: 0.9768 - val_loss: 5.9578 - val_acc: 0.4759\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 3s 64us/step - loss: 0.1489 - acc: 0.9824 - val_loss: 5.9853 - val_acc: 0.4709\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 0.1331 - acc: 0.9845 - val_loss: 6.1553 - val_acc: 0.4761\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 3s 64us/step - loss: 0.1190 - acc: 0.9877 - val_loss: 6.1231 - val_acc: 0.4756\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 0.1122 - acc: 0.9883 - val_loss: 6.1710 - val_acc: 0.4755\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 0.1008 - acc: 0.9906 - val_loss: 6.2072 - val_acc: 0.4794\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 3s 64us/step - loss: 0.0914 - acc: 0.9926 - val_loss: 6.2808 - val_acc: 0.4774\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 0.0833 - acc: 0.9937 - val_loss: 6.4095 - val_acc: 0.4756\n",
      "Numbers of exp: 1, ce_weight: 0.30\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 5.9824 - acc: 0.3365 - val_loss: 6.9389 - val_acc: 0.3084\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 4.3292 - acc: 0.4484 - val_loss: 4.7220 - val_acc: 0.4036\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 3.9316 - acc: 0.4865 - val_loss: 4.4531 - val_acc: 0.4244\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 3.6569 - acc: 0.5100 - val_loss: 4.1648 - val_acc: 0.4590\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 3.4398 - acc: 0.5339 - val_loss: 4.2580 - val_acc: 0.4486\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 3.2556 - acc: 0.5536 - val_loss: 4.1196 - val_acc: 0.4596\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 3.0846 - acc: 0.5681 - val_loss: 3.9741 - val_acc: 0.4711\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 2.9326 - acc: 0.5856 - val_loss: 4.0601 - val_acc: 0.4708\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 2.7838 - acc: 0.6026 - val_loss: 3.9237 - val_acc: 0.4809\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 2.6410 - acc: 0.6165 - val_loss: 3.9819 - val_acc: 0.4766\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 2.5026 - acc: 0.6329 - val_loss: 3.9479 - val_acc: 0.4836\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 2.3706 - acc: 0.6471 - val_loss: 3.9765 - val_acc: 0.4818\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 2.2515 - acc: 0.6611 - val_loss: 4.0906 - val_acc: 0.4696\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 2.1316 - acc: 0.6748 - val_loss: 4.2207 - val_acc: 0.4730\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 2.0071 - acc: 0.6909 - val_loss: 4.0507 - val_acc: 0.4850\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 1.8945 - acc: 0.7053 - val_loss: 4.0983 - val_acc: 0.4842\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 1.7904 - acc: 0.7169 - val_loss: 4.1105 - val_acc: 0.4832\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 1.6713 - acc: 0.7322 - val_loss: 4.0988 - val_acc: 0.4897\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 1.5657 - acc: 0.7444 - val_loss: 4.3349 - val_acc: 0.4714\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 1.4874 - acc: 0.7552 - val_loss: 4.3430 - val_acc: 0.4716\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 1.3655 - acc: 0.7747 - val_loss: 4.3810 - val_acc: 0.4811\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 1.2673 - acc: 0.7870 - val_loss: 4.5702 - val_acc: 0.4742\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 1.1725 - acc: 0.8014 - val_loss: 4.6903 - val_acc: 0.4614\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 1.0995 - acc: 0.8104 - val_loss: 4.5803 - val_acc: 0.4804\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 1.0173 - acc: 0.8238 - val_loss: 4.5423 - val_acc: 0.4825\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 0.9337 - acc: 0.8373 - val_loss: 4.6705 - val_acc: 0.4901\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 0.8529 - acc: 0.8496 - val_loss: 4.8271 - val_acc: 0.4687\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 0.7844 - acc: 0.8624 - val_loss: 4.8758 - val_acc: 0.4811\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 0.7171 - acc: 0.8756 - val_loss: 5.1860 - val_acc: 0.4707\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 0.6556 - acc: 0.8840 - val_loss: 5.1218 - val_acc: 0.4740\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 0.5899 - acc: 0.8953 - val_loss: 5.2679 - val_acc: 0.4715\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.5337 - acc: 0.9056 - val_loss: 5.1852 - val_acc: 0.4762\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 0.4891 - acc: 0.9149 - val_loss: 5.3796 - val_acc: 0.4772\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 0.4383 - acc: 0.9230 - val_loss: 5.4864 - val_acc: 0.4712\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 0.3901 - acc: 0.9338 - val_loss: 5.4981 - val_acc: 0.4746\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 0.3506 - acc: 0.9421 - val_loss: 5.6694 - val_acc: 0.4725\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 0.3219 - acc: 0.9468 - val_loss: 5.6106 - val_acc: 0.4794165 - \n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 0.2893 - acc: 0.9538 - val_loss: 5.7860 - val_acc: 0.4774\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 0.2570 - acc: 0.9598 - val_loss: 5.8385 - val_acc: 0.4778\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 0.2320 - acc: 0.9658 - val_loss: 5.8539 - val_acc: 0.4680\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 0.2112 - acc: 0.9701 - val_loss: 5.8882 - val_acc: 0.4798\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.1880 - acc: 0.9743 - val_loss: 5.9904 - val_acc: 0.4721\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 4s 73us/step - loss: 0.1669 - acc: 0.9782 - val_loss: 6.1285 - val_acc: 0.4761\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 0.1563 - acc: 0.9800 - val_loss: 6.0929 - val_acc: 0.4773\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 0.1358 - acc: 0.9844 - val_loss: 6.2017 - val_acc: 0.4818\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 0.1224 - acc: 0.9865 - val_loss: 6.2013 - val_acc: 0.4786\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 0.1115 - acc: 0.9889 - val_loss: 6.3058 - val_acc: 0.4787\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 0.1031 - acc: 0.9899 - val_loss: 6.3316 - val_acc: 0.4766\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 0.0919 - acc: 0.9923 - val_loss: 6.3279 - val_acc: 0.4796\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 0.0844 - acc: 0.9928 - val_loss: 6.5092 - val_acc: 0.4833\n",
      "Numbers of exp: 2, ce_weight: 0.50\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 5.9737 - acc: 0.3285 - val_loss: 6.0722 - val_acc: 0.3426\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 4.3791 - acc: 0.4426 - val_loss: 4.8017 - val_acc: 0.3932\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 3.9449 - acc: 0.4833 - val_loss: 4.4195 - val_acc: 0.4352\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 3.6681 - acc: 0.5092 - val_loss: 4.1931 - val_acc: 0.4524\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 3.4429 - acc: 0.5320 - val_loss: 4.1482 - val_acc: 0.4555\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 3.2539 - acc: 0.5503 - val_loss: 4.1219 - val_acc: 0.4566\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 3.0818 - acc: 0.5721 - val_loss: 3.9983 - val_acc: 0.4711\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 2.9222 - acc: 0.5877 - val_loss: 4.1148 - val_acc: 0.4597\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 2.7810 - acc: 0.6016 - val_loss: 4.0432 - val_acc: 0.4691\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 2.6429 - acc: 0.6185 - val_loss: 4.0630 - val_acc: 0.4659\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 2.5055 - acc: 0.6308 - val_loss: 4.2303 - val_acc: 0.4503\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 2.3642 - acc: 0.6485 - val_loss: 3.9027 - val_acc: 0.4898\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 2.2421 - acc: 0.6613 - val_loss: 4.0108 - val_acc: 0.4785\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 2.1161 - acc: 0.6760 - val_loss: 4.0445 - val_acc: 0.4845\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 1.9814 - acc: 0.6931 - val_loss: 4.1765 - val_acc: 0.4667\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 1.8705 - acc: 0.7069 - val_loss: 4.0527 - val_acc: 0.4773\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 1.7434 - acc: 0.7237 - val_loss: 4.2104 - val_acc: 0.4736\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 1.6291 - acc: 0.7358 - val_loss: 4.1636 - val_acc: 0.4835\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 1.5210 - acc: 0.7529 - val_loss: 4.1796 - val_acc: 0.4901\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 1.4227 - acc: 0.7635 - val_loss: 4.2565 - val_acc: 0.4866\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 1.3171 - acc: 0.7802 - val_loss: 4.5900 - val_acc: 0.4703\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 1.2164 - acc: 0.7934 - val_loss: 4.4980 - val_acc: 0.4784\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 1.1209 - acc: 0.8072 - val_loss: 4.4495 - val_acc: 0.4881\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 1.0299 - acc: 0.8210 - val_loss: 4.5306 - val_acc: 0.4810\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 0.9444 - acc: 0.8364 - val_loss: 4.6817 - val_acc: 0.4830\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 0.8688 - acc: 0.8475 - val_loss: 4.8348 - val_acc: 0.4797\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 0.7959 - acc: 0.8582 - val_loss: 5.0191 - val_acc: 0.4757\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 0.7205 - acc: 0.8726 - val_loss: 4.9394 - val_acc: 0.4752\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 0.6496 - acc: 0.8855 - val_loss: 5.0999 - val_acc: 0.4783\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 0.5986 - acc: 0.8934 - val_loss: 5.0664 - val_acc: 0.4827\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 0.5339 - acc: 0.9037 - val_loss: 5.1065 - val_acc: 0.4713\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 0.4798 - acc: 0.9156 - val_loss: 5.3321 - val_acc: 0.4754\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 0.4308 - acc: 0.9248 - val_loss: 5.5267 - val_acc: 0.4798\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 0.3877 - acc: 0.9336 - val_loss: 5.3772 - val_acc: 0.4791\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 0.3518 - acc: 0.9411 - val_loss: 5.4325 - val_acc: 0.4845\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 0.3145 - acc: 0.9474 - val_loss: 5.5058 - val_acc: 0.4789\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 0.2764 - acc: 0.9555 - val_loss: 5.6910 - val_acc: 0.4736\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 0.2438 - acc: 0.9629 - val_loss: 5.7285 - val_acc: 0.4815\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 0.2182 - acc: 0.9679 - val_loss: 5.7006 - val_acc: 0.4784\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 0.1965 - acc: 0.9728 - val_loss: 5.8050 - val_acc: 0.4835\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 0.1767 - acc: 0.9768 - val_loss: 5.8919 - val_acc: 0.4850\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 0.1545 - acc: 0.9802 - val_loss: 6.1039 - val_acc: 0.4775\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 0.1361 - acc: 0.9848 - val_loss: 5.9697 - val_acc: 0.4827\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 0.1249 - acc: 0.9871 - val_loss: 6.0443 - val_acc: 0.4862\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 0.1129 - acc: 0.9884 - val_loss: 6.0949 - val_acc: 0.4847\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 0.1021 - acc: 0.9904 - val_loss: 6.1609 - val_acc: 0.4798\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 0.0932 - acc: 0.9919 - val_loss: 6.1266 - val_acc: 0.4860\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 0.0843 - acc: 0.9930 - val_loss: 6.1775 - val_acc: 0.4856\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 0.0774 - acc: 0.9947 - val_loss: 6.3693 - val_acc: 0.4843\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 0.0691 - acc: 0.9957 - val_loss: 6.3548 - val_acc: 0.4882\n",
      "Numbers of exp: 3, ce_weight: 0.70\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 6.0354 - acc: 0.3289 - val_loss: 6.2710 - val_acc: 0.3296\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 4.3846 - acc: 0.4418 - val_loss: 4.6303 - val_acc: 0.4213\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 3.9804 - acc: 0.4829 - val_loss: 4.3572 - val_acc: 0.4345\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 3.7161 - acc: 0.5070 - val_loss: 4.2170 - val_acc: 0.4554\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 3.5013 - acc: 0.5309 - val_loss: 4.1474 - val_acc: 0.4546\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 3.3239 - acc: 0.5488 - val_loss: 4.1622 - val_acc: 0.4572\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 3.1613 - acc: 0.5627 - val_loss: 4.0525 - val_acc: 0.4704\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 3.0080 - acc: 0.5796 - val_loss: 3.9004 - val_acc: 0.4808\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 2.8637 - acc: 0.5959 - val_loss: 3.8843 - val_acc: 0.4825\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 2.7315 - acc: 0.6081 - val_loss: 4.0267 - val_acc: 0.4722\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 2.5986 - acc: 0.6238 - val_loss: 3.9178 - val_acc: 0.4840\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 2.4741 - acc: 0.6383 - val_loss: 3.8452 - val_acc: 0.4938\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 2.3548 - acc: 0.6529 - val_loss: 4.1178 - val_acc: 0.4755\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 2.2294 - acc: 0.6656 - val_loss: 4.0817 - val_acc: 0.4751\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 2.1175 - acc: 0.6807 - val_loss: 4.2851 - val_acc: 0.4622\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 2.0009 - acc: 0.6937 - val_loss: 4.0860 - val_acc: 0.4738\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 1.8806 - acc: 0.7076 - val_loss: 4.0521 - val_acc: 0.4923\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 1.7826 - acc: 0.7205 - val_loss: 4.1775 - val_acc: 0.4811\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 1.6656 - acc: 0.7352 - val_loss: 4.2615 - val_acc: 0.4790\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 1.5675 - acc: 0.7484 - val_loss: 4.3019 - val_acc: 0.4821\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 1.4698 - acc: 0.7601 - val_loss: 4.2739 - val_acc: 0.4834\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 1.3697 - acc: 0.7735 - val_loss: 4.3312 - val_acc: 0.4803\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 1.2833 - acc: 0.7862 - val_loss: 4.4144 - val_acc: 0.4891\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 1.1881 - acc: 0.8012 - val_loss: 4.5758 - val_acc: 0.4804\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 1.1096 - acc: 0.8095 - val_loss: 4.7443 - val_acc: 0.4737\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 1.0106 - acc: 0.8269 - val_loss: 4.7278 - val_acc: 0.4760\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.9493 - acc: 0.8351 - val_loss: 4.8202 - val_acc: 0.4723\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 0.8657 - acc: 0.8474 - val_loss: 4.9293 - val_acc: 0.4747\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.8060 - acc: 0.8584 - val_loss: 4.9394 - val_acc: 0.4816\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.7379 - acc: 0.8690 - val_loss: 5.1380 - val_acc: 0.4705\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 0.6760 - acc: 0.8802 - val_loss: 5.2159 - val_acc: 0.4707\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.6219 - acc: 0.8902 - val_loss: 5.1988 - val_acc: 0.4785\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.5652 - acc: 0.8994 - val_loss: 5.2248 - val_acc: 0.4759\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.5139 - acc: 0.9079 - val_loss: 5.3934 - val_acc: 0.4729\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.4600 - acc: 0.9186 - val_loss: 5.4556 - val_acc: 0.4663\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.4321 - acc: 0.9239 - val_loss: 5.4956 - val_acc: 0.4782\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 0.3917 - acc: 0.9332 - val_loss: 5.5795 - val_acc: 0.4769\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 0.3476 - acc: 0.9402 - val_loss: 5.6328 - val_acc: 0.4786\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 0.3130 - acc: 0.9476 - val_loss: 5.7535 - val_acc: 0.4724\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.2822 - acc: 0.9533 - val_loss: 5.8263 - val_acc: 0.4762\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.2494 - acc: 0.9605 - val_loss: 5.8561 - val_acc: 0.4767\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 0.2340 - acc: 0.9642 - val_loss: 5.9179 - val_acc: 0.4770\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 0.2088 - acc: 0.9697 - val_loss: 6.1334 - val_acc: 0.4740\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 0.1877 - acc: 0.9733 - val_loss: 6.0520 - val_acc: 0.4849\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 0.1661 - acc: 0.9777 - val_loss: 6.1680 - val_acc: 0.4696\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 0.1503 - acc: 0.9821 - val_loss: 6.2632 - val_acc: 0.4761\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 0.1343 - acc: 0.9849 - val_loss: 6.2426 - val_acc: 0.4766\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 0.1214 - acc: 0.9870 - val_loss: 6.3023 - val_acc: 0.4753\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 0.1115 - acc: 0.9887 - val_loss: 6.3075 - val_acc: 0.4809\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 0.1029 - acc: 0.9903 - val_loss: 6.3797 - val_acc: 0.4718\n",
      "Numbers of exp: 4, ce_weight: 1.00\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 5.9159 - acc: 0.3335 - val_loss: 6.7437 - val_acc: 0.3200\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 4.3230 - acc: 0.4489 - val_loss: 5.0093 - val_acc: 0.3889\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 3.9040 - acc: 0.4886 - val_loss: 4.4595 - val_acc: 0.4258\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 3.6406 - acc: 0.5147 - val_loss: 4.0872 - val_acc: 0.4607\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 3.4312 - acc: 0.5336 - val_loss: 4.0014 - val_acc: 0.4679\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 3.2433 - acc: 0.5548 - val_loss: 4.0424 - val_acc: 0.4599\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 3.0768 - acc: 0.5720 - val_loss: 4.1271 - val_acc: 0.4609\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 2.9244 - acc: 0.5865 - val_loss: 4.0439 - val_acc: 0.4635\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 2.7682 - acc: 0.6038 - val_loss: 4.0449 - val_acc: 0.4662\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 2.6422 - acc: 0.6177 - val_loss: 3.9568 - val_acc: 0.4781\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 2.5015 - acc: 0.6349 - val_loss: 4.0009 - val_acc: 0.4737\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 2.3681 - acc: 0.6504 - val_loss: 3.9661 - val_acc: 0.4762\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 2.2337 - acc: 0.6657 - val_loss: 3.9429 - val_acc: 0.4811\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 2.1145 - acc: 0.6796 - val_loss: 3.9897 - val_acc: 0.4821\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 1.9909 - acc: 0.6941 - val_loss: 4.0615 - val_acc: 0.4802\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 1.8750 - acc: 0.7083 - val_loss: 4.1014 - val_acc: 0.4860\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 1.7608 - acc: 0.7223 - val_loss: 4.0690 - val_acc: 0.4806\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 1.6510 - acc: 0.7368 - val_loss: 4.2552 - val_acc: 0.4839\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 1.5581 - acc: 0.7488 - val_loss: 4.4393 - val_acc: 0.4739\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 1.4348 - acc: 0.7666 - val_loss: 4.4295 - val_acc: 0.4829\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 1.3517 - acc: 0.7753 - val_loss: 4.4293 - val_acc: 0.4794\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 1.2345 - acc: 0.7952 - val_loss: 4.5110 - val_acc: 0.4724\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 3s 70us/step - loss: 1.1514 - acc: 0.8056 - val_loss: 4.5431 - val_acc: 0.4796\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 1.0634 - acc: 0.8188 - val_loss: 4.5797 - val_acc: 0.4719\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.9811 - acc: 0.8298 - val_loss: 4.7552 - val_acc: 0.4691\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.8920 - acc: 0.8443 - val_loss: 4.8537 - val_acc: 0.4713\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.8063 - acc: 0.8606 - val_loss: 4.8800 - val_acc: 0.4739\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.7410 - acc: 0.8705 - val_loss: 4.9024 - val_acc: 0.4734\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.6778 - acc: 0.8804 - val_loss: 5.0071 - val_acc: 0.4737\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.6126 - acc: 0.8939 - val_loss: 5.1552 - val_acc: 0.4768\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.5569 - acc: 0.9028 - val_loss: 5.1223 - val_acc: 0.4809\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.5050 - acc: 0.9111 - val_loss: 5.2483 - val_acc: 0.4686\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.4465 - acc: 0.9227 - val_loss: 5.3119 - val_acc: 0.4733\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.4079 - acc: 0.9302 - val_loss: 5.5085 - val_acc: 0.4716\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.3659 - acc: 0.9380 - val_loss: 5.6073 - val_acc: 0.4714\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.3365 - acc: 0.9434 - val_loss: 5.6584 - val_acc: 0.4692\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 4s 71us/step - loss: 0.2968 - acc: 0.9520 - val_loss: 5.6716 - val_acc: 0.4711\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 3s 70us/step - loss: 0.2649 - acc: 0.9591 - val_loss: 5.7541 - val_acc: 0.4764\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.2382 - acc: 0.9645 - val_loss: 5.7646 - val_acc: 0.4749\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.2141 - acc: 0.9681 - val_loss: 5.9078 - val_acc: 0.4792\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.1908 - acc: 0.9743 - val_loss: 5.9536 - val_acc: 0.4767\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.1756 - acc: 0.9765 - val_loss: 6.0780 - val_acc: 0.4723\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.1538 - acc: 0.9804 - val_loss: 6.1258 - val_acc: 0.4694\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.1388 - acc: 0.9829 - val_loss: 6.1086 - val_acc: 0.4755\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.1239 - acc: 0.9864 - val_loss: 6.2341 - val_acc: 0.4785\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.1102 - acc: 0.9896 - val_loss: 6.2289 - val_acc: 0.4826\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 0.0975 - acc: 0.9912 - val_loss: 6.3548 - val_acc: 0.4782\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0896 - acc: 0.9922 - val_loss: 6.3128 - val_acc: 0.4792\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 3s 68us/step - loss: 0.0825 - acc: 0.9935 - val_loss: 6.3994 - val_acc: 0.4826\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 0.0727 - acc: 0.9954 - val_loss: 6.4526 - val_acc: 0.4765\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "results = {}\n",
    "\n",
    "for i, ce_w in enumerate(ce_weights_list):\n",
    "    print(\"Numbers of exp: %i, ce_weight: %.2f\" % (i, ce_w))\n",
    "\n",
    "    model = build_mlp(input_shape=x_train.shape[1:])\n",
    "    model.summary()\n",
    "    optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
    "    \"\"\"Code Here\n",
    "    將自定義的 loss function 加入模型\n",
    "    \"\"\"\n",
    "    model.compile(loss=focal_loss(), metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "    model.fit(x_train, y_train, \n",
    "              epochs=EPOCHS, \n",
    "              batch_size=BATCH_SIZE, \n",
    "              validation_data=(x_test, y_test), \n",
    "              shuffle=True\n",
    "             )\n",
    "    \n",
    "    # Collect results\n",
    "    exp_name_tag = (\"exp-%s\" % (i))\n",
    "    results[exp_name_tag] = {'train-loss': model.history.history[\"loss\"],\n",
    "                             'valid-loss': model.history.history[\"val_loss\"],\n",
    "                             'train-acc': model.history.history[\"acc\"],\n",
    "                             'valid-acc': model.history.history[\"val_acc\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as mplcm\n",
    "import matplotlib.colors as colors\n",
    "%matplotlib inline\n",
    "NUM_COLORS = len(results.keys())\n",
    "\n",
    "cm = plt.get_cmap('gist_rainbow')\n",
    "cNorm  = colors.Normalize(vmin=0, vmax=NUM_COLORS-1)\n",
    "scalarMap = mplcm.ScalarMappable(norm=cNorm, cmap=cm)\n",
    "color_bar = [scalarMap.to_rgba(i) for i in range(NUM_COLORS)]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-loss'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-loss'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Loss\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-acc'])),results[cond]['train-acc'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-acc'])),results[cond]['valid-acc'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finlab",
   "language": "python",
   "name": "finlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
