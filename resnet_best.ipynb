{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Richard\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Richard\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Richard\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Richard\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Richard\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Richard\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Richard\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 5)                 51383301  \n",
      "=================================================================\n",
      "Total params: 74,971,013\n",
      "Trainable params: 74,917,893\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#1. 載入相關模組\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications import ResNet50\n",
    "from keras import models\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "# 以訓練好的 ResNet50 為基礎來建立模型，\n",
    "# 捨棄 ResNet50 頂層的 fully connected layers\n",
    "\n",
    "cnn_base = ResNet50(include_top=False, weights='imagenet',input_shape=(224, 224, 3))\n",
    "\n",
    "\n",
    "classify = models.Sequential()\n",
    "classify.add(layers.Flatten())\n",
    "classify.add(layers.Dense(512, activation='relu'))\n",
    "classify.add(layers.Dropout(0.5))\n",
    "classify.add(layers.Dense(5, activation='sigmoid'))\n",
    "#classify.summary()\n",
    "\n",
    "#5. 將CNN base與自定的分類器組合起來\n",
    "model = models.Sequential()\n",
    "model.add(cnn_base)\n",
    "model.add(classify)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2322 images belonging to 5 classes.\n",
      "Found 481 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_batches = ImageDataGenerator(\n",
    "        rotation_range = 30,        #rotation_range：整數，資料提升時圖片隨機轉動的角度。隨機選擇圖片的角度，是一個0~180的度數，取值為0~180。\n",
    "        width_shift_range = 0.3,   #width_shift_range：浮點數，圖片寬度的某個比例，資料提升時圖片隨機水平偏移的幅度\n",
    "        height_shift_range = 0.3,  #height_shift_range：浮點數，圖片高度的某個比例，資料提升時圖片隨機豎直偏移的幅度。\n",
    "        shear_range = 0.3,\n",
    "        zoom_range = 0.4,\n",
    "        channel_shift_range = 0.2,\n",
    "        fill_mode = 'nearest',\n",
    "        horizontal_flip = True,\n",
    "        vertical_flip = False).flow_from_directory(\n",
    "    'training', target_size=(224,224), class_mode='categorical', batch_size=10)\n",
    "\n",
    "valid_batches = ImageDataGenerator(\n",
    "        rotation_range = 30,\n",
    "        width_shift_range = 0.3,\n",
    "        height_shift_range = 0.3,\n",
    "        shear_range = 0.3,\n",
    "        zoom_range = 0.4,\n",
    "        channel_shift_range = 0.2,\n",
    "        fill_mode = 'nearest',\n",
    "        horizontal_flip = True,\n",
    "        vertical_flip = False).flow_from_directory(\n",
    "    'testing', target_size=(224,224), class_mode='categorical', batch_size=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 29s - loss: 1.6657 - acc: 0.3060 - val_loss: 1.5682 - val_acc: 0.2648\n",
      "Epoch 2/100\n",
      " - 15s - loss: 1.4688 - acc: 0.4720 - val_loss: 1.5885 - val_acc: 0.4012\n",
      "Epoch 3/100\n",
      " - 15s - loss: 1.2058 - acc: 0.5840 - val_loss: 1.5391 - val_acc: 0.4705\n",
      "Epoch 4/100\n",
      " - 15s - loss: 1.0304 - acc: 0.6360 - val_loss: 1.6514 - val_acc: 0.4868\n",
      "Epoch 5/100\n",
      " - 16s - loss: 1.0988 - acc: 0.6420 - val_loss: 1.3334 - val_acc: 0.5214\n",
      "Epoch 6/100\n",
      " - 15s - loss: 0.8841 - acc: 0.7480 - val_loss: 1.3976 - val_acc: 0.5275\n",
      "Epoch 7/100\n",
      " - 15s - loss: 0.7946 - acc: 0.7380 - val_loss: 1.3504 - val_acc: 0.5703\n",
      "Epoch 8/100\n",
      " - 15s - loss: 0.7743 - acc: 0.7480 - val_loss: 1.3331 - val_acc: 0.5927\n",
      "Epoch 9/100\n",
      " - 15s - loss: 0.7553 - acc: 0.7400 - val_loss: 1.1930 - val_acc: 0.6049\n",
      "Epoch 10/100\n",
      " - 15s - loss: 0.7254 - acc: 0.7601 - val_loss: 1.1223 - val_acc: 0.5927\n",
      "Epoch 11/100\n",
      " - 15s - loss: 0.6016 - acc: 0.8060 - val_loss: 1.4511 - val_acc: 0.5601\n",
      "Epoch 12/100\n",
      " - 15s - loss: 0.6395 - acc: 0.7960 - val_loss: 1.1365 - val_acc: 0.6456\n",
      "Epoch 13/100\n",
      " - 15s - loss: 0.6665 - acc: 0.7760 - val_loss: 1.2530 - val_acc: 0.5906\n",
      "Epoch 14/100\n",
      " - 15s - loss: 0.6515 - acc: 0.7879 - val_loss: 1.1272 - val_acc: 0.6090\n",
      "Epoch 15/100\n",
      " - 15s - loss: 0.6460 - acc: 0.7960 - val_loss: 1.2911 - val_acc: 0.5804\n",
      "Epoch 16/100\n",
      " - 15s - loss: 0.4946 - acc: 0.8320 - val_loss: 1.3351 - val_acc: 0.6110\n",
      "Epoch 17/100\n",
      " - 15s - loss: 0.6124 - acc: 0.7980 - val_loss: 1.1170 - val_acc: 0.6171\n",
      "Epoch 18/100\n",
      " - 15s - loss: 0.5671 - acc: 0.8140 - val_loss: 1.1120 - val_acc: 0.6069\n",
      "Epoch 19/100\n",
      " - 15s - loss: 0.5050 - acc: 0.8343 - val_loss: 1.2147 - val_acc: 0.6008\n",
      "Epoch 20/100\n",
      " - 15s - loss: 0.5686 - acc: 0.8160 - val_loss: 1.1269 - val_acc: 0.6456\n",
      "Epoch 21/100\n",
      " - 15s - loss: 0.5738 - acc: 0.8360 - val_loss: 1.2044 - val_acc: 0.6151\n",
      "Epoch 22/100\n",
      " - 15s - loss: 0.4726 - acc: 0.8460 - val_loss: 1.0815 - val_acc: 0.6334\n",
      "Epoch 23/100\n",
      " - 15s - loss: 0.4101 - acc: 0.8700 - val_loss: 1.1221 - val_acc: 0.6599\n",
      "Epoch 24/100\n",
      " - 15s - loss: 0.4298 - acc: 0.8720 - val_loss: 1.1853 - val_acc: 0.6171\n",
      "Epoch 25/100\n",
      " - 15s - loss: 0.4300 - acc: 0.8540 - val_loss: 1.2241 - val_acc: 0.6069\n",
      "Epoch 26/100\n",
      " - 15s - loss: 0.4900 - acc: 0.8620 - val_loss: 1.0503 - val_acc: 0.6191\n",
      "Epoch 27/100\n",
      " - 15s - loss: 0.4210 - acc: 0.8520 - val_loss: 1.0242 - val_acc: 0.6497\n",
      "Epoch 28/100\n",
      " - 15s - loss: 0.4880 - acc: 0.8480 - val_loss: 0.9768 - val_acc: 0.6701\n",
      "Epoch 29/100\n",
      " - 15s - loss: 0.4679 - acc: 0.8380 - val_loss: 0.9723 - val_acc: 0.6497\n",
      "Epoch 30/100\n",
      " - 15s - loss: 0.4095 - acc: 0.8780 - val_loss: 1.0949 - val_acc: 0.6497\n",
      "Epoch 31/100\n",
      " - 15s - loss: 0.4251 - acc: 0.8440 - val_loss: 1.0134 - val_acc: 0.6293\n",
      "Epoch 32/100\n",
      " - 15s - loss: 0.3539 - acc: 0.8860 - val_loss: 0.9874 - val_acc: 0.6904\n",
      "Epoch 33/100\n",
      " - 15s - loss: 0.3868 - acc: 0.8561 - val_loss: 1.1119 - val_acc: 0.6517\n",
      "Epoch 34/100\n",
      " - 15s - loss: 0.4152 - acc: 0.8680 - val_loss: 1.0946 - val_acc: 0.6640\n",
      "Epoch 35/100\n",
      " - 15s - loss: 0.4055 - acc: 0.8600 - val_loss: 0.9391 - val_acc: 0.7047\n",
      "Epoch 36/100\n",
      " - 15s - loss: 0.3400 - acc: 0.8940 - val_loss: 1.0320 - val_acc: 0.6558\n",
      "Epoch 37/100\n",
      " - 15s - loss: 0.3750 - acc: 0.8840 - val_loss: 0.9944 - val_acc: 0.6843\n",
      "Epoch 38/100\n",
      " - 15s - loss: 0.3128 - acc: 0.8960 - val_loss: 0.9615 - val_acc: 0.6721\n",
      "Epoch 39/100\n",
      " - 15s - loss: 0.2944 - acc: 0.8940 - val_loss: 0.9679 - val_acc: 0.6904\n",
      "Epoch 40/100\n",
      " - 15s - loss: 0.2662 - acc: 0.9120 - val_loss: 1.0179 - val_acc: 0.6904\n",
      "Epoch 41/100\n",
      " - 15s - loss: 0.4202 - acc: 0.8720 - val_loss: 1.0222 - val_acc: 0.6843\n",
      "Epoch 42/100\n",
      " - 15s - loss: 0.3780 - acc: 0.8840 - val_loss: 0.9456 - val_acc: 0.6823\n",
      "Epoch 43/100\n",
      " - 15s - loss: 0.3269 - acc: 0.8940 - val_loss: 0.9410 - val_acc: 0.6864\n",
      "Epoch 44/100\n",
      " - 15s - loss: 0.3117 - acc: 0.9020 - val_loss: 1.0278 - val_acc: 0.6741\n",
      "Epoch 45/100\n",
      " - 15s - loss: 0.3589 - acc: 0.8780 - val_loss: 1.0649 - val_acc: 0.6619\n",
      "Epoch 46/100\n",
      " - 15s - loss: 0.2790 - acc: 0.9000 - val_loss: 0.9668 - val_acc: 0.6782\n",
      "Epoch 47/100\n",
      " - 15s - loss: 0.3743 - acc: 0.8781 - val_loss: 0.9575 - val_acc: 0.6864\n",
      "Epoch 48/100\n",
      " - 15s - loss: 0.2877 - acc: 0.8980 - val_loss: 0.8929 - val_acc: 0.7210\n",
      "Epoch 49/100\n",
      " - 15s - loss: 0.2295 - acc: 0.9280 - val_loss: 1.0229 - val_acc: 0.6639\n",
      "Epoch 50/100\n",
      " - 15s - loss: 0.3835 - acc: 0.8780 - val_loss: 0.9874 - val_acc: 0.6925\n",
      "Epoch 51/100\n",
      " - 15s - loss: 0.3053 - acc: 0.9020 - val_loss: 0.9715 - val_acc: 0.6660\n",
      "Epoch 52/100\n",
      " - 15s - loss: 0.2651 - acc: 0.9160 - val_loss: 0.9663 - val_acc: 0.6904\n",
      "Epoch 53/100\n",
      " - 15s - loss: 0.2758 - acc: 0.8940 - val_loss: 1.0041 - val_acc: 0.6701\n",
      "Epoch 54/100\n",
      " - 15s - loss: 0.2577 - acc: 0.9060 - val_loss: 0.9184 - val_acc: 0.7088\n",
      "Epoch 55/100\n",
      " - 15s - loss: 0.3205 - acc: 0.9200 - val_loss: 0.9760 - val_acc: 0.6864\n",
      "Epoch 56/100\n",
      " - 14s - loss: 0.2662 - acc: 0.9200 - val_loss: 0.9705 - val_acc: 0.6843\n",
      "Epoch 57/100\n",
      " - 15s - loss: 0.2832 - acc: 0.9080 - val_loss: 1.0003 - val_acc: 0.6965\n",
      "Epoch 58/100\n",
      " - 15s - loss: 0.1899 - acc: 0.9240 - val_loss: 1.0958 - val_acc: 0.6415\n",
      "Epoch 59/100\n",
      " - 15s - loss: 0.3323 - acc: 0.8920 - val_loss: 0.9882 - val_acc: 0.6965\n",
      "Epoch 60/100\n",
      " - 15s - loss: 0.2382 - acc: 0.9040 - val_loss: 1.0307 - val_acc: 0.6965\n",
      "Epoch 61/100\n",
      " - 14s - loss: 0.2495 - acc: 0.9120 - val_loss: 0.9821 - val_acc: 0.6986\n",
      "Epoch 62/100\n",
      " - 14s - loss: 0.2271 - acc: 0.9260 - val_loss: 1.0412 - val_acc: 0.6762\n",
      "Epoch 63/100\n",
      " - 15s - loss: 0.2079 - acc: 0.9140 - val_loss: 0.9552 - val_acc: 0.7149\n",
      "Epoch 64/100\n",
      " - 15s - loss: 0.2316 - acc: 0.9240 - val_loss: 1.0845 - val_acc: 0.6762\n",
      "Epoch 65/100\n",
      " - 16s - loss: 0.2671 - acc: 0.9160 - val_loss: 1.0195 - val_acc: 0.6701\n",
      "Epoch 66/100\n",
      " - 15s - loss: 0.2819 - acc: 0.9043 - val_loss: 1.0251 - val_acc: 0.6823\n",
      "Epoch 67/100\n",
      " - 15s - loss: 0.2158 - acc: 0.9320 - val_loss: 1.0390 - val_acc: 0.7149\n",
      "Epoch 68/100\n",
      " - 15s - loss: 0.2079 - acc: 0.9220 - val_loss: 0.9597 - val_acc: 0.6965\n",
      "Epoch 69/100\n",
      " - 15s - loss: 0.2631 - acc: 0.9080 - val_loss: 1.0363 - val_acc: 0.6925\n",
      "Epoch 70/100\n",
      " - 15s - loss: 0.2382 - acc: 0.9280 - val_loss: 1.0848 - val_acc: 0.7149\n",
      "Epoch 71/100\n",
      " - 15s - loss: 0.2615 - acc: 0.9040 - val_loss: 1.0374 - val_acc: 0.6802\n",
      "Epoch 72/100\n",
      " - 15s - loss: 0.2034 - acc: 0.9220 - val_loss: 0.9933 - val_acc: 0.7128\n",
      "Epoch 73/100\n",
      " - 15s - loss: 0.2321 - acc: 0.9360 - val_loss: 1.1144 - val_acc: 0.6864\n",
      "Epoch 74/100\n",
      " - 15s - loss: 0.2165 - acc: 0.9100 - val_loss: 0.9239 - val_acc: 0.7271\n",
      "Epoch 75/100\n",
      " - 15s - loss: 0.3143 - acc: 0.9241 - val_loss: 0.9791 - val_acc: 0.6945\n",
      "Epoch 76/100\n",
      " - 15s - loss: 0.1910 - acc: 0.9460 - val_loss: 0.8568 - val_acc: 0.6904\n",
      "Epoch 77/100\n",
      " - 15s - loss: 0.1915 - acc: 0.9360 - val_loss: 0.9877 - val_acc: 0.7006\n",
      "Epoch 78/100\n",
      " - 15s - loss: 0.2001 - acc: 0.9420 - val_loss: 1.0407 - val_acc: 0.6945\n",
      "Epoch 79/100\n",
      " - 15s - loss: 0.1837 - acc: 0.9340 - val_loss: 0.9136 - val_acc: 0.7128\n",
      "Epoch 80/100\n",
      " - 15s - loss: 0.1440 - acc: 0.9500 - val_loss: 0.9802 - val_acc: 0.7026\n",
      "Epoch 81/100\n",
      " - 16s - loss: 0.1629 - acc: 0.9400 - val_loss: 1.2964 - val_acc: 0.6599\n",
      "Epoch 82/100\n",
      " - 16s - loss: 0.2287 - acc: 0.9220 - val_loss: 0.9800 - val_acc: 0.7230\n",
      "Epoch 83/100\n",
      " - 15s - loss: 0.1832 - acc: 0.9380 - val_loss: 0.9663 - val_acc: 0.7413\n",
      "Epoch 84/100\n",
      " - 15s - loss: 0.2183 - acc: 0.9280 - val_loss: 1.0299 - val_acc: 0.6925\n",
      "Epoch 85/100\n",
      " - 15s - loss: 0.1893 - acc: 0.9460 - val_loss: 0.9406 - val_acc: 0.7271\n",
      "Epoch 86/100\n",
      " - 15s - loss: 0.1990 - acc: 0.9260 - val_loss: 1.0094 - val_acc: 0.7128\n",
      "Epoch 87/100\n",
      " - 15s - loss: 0.2306 - acc: 0.9180 - val_loss: 0.8898 - val_acc: 0.7210\n",
      "Epoch 88/100\n",
      " - 15s - loss: 0.1771 - acc: 0.9480 - val_loss: 1.0920 - val_acc: 0.6782\n",
      "Epoch 89/100\n",
      " - 15s - loss: 0.2207 - acc: 0.9360 - val_loss: 1.0207 - val_acc: 0.6802\n",
      "Epoch 90/100\n",
      " - 15s - loss: 0.2014 - acc: 0.9380 - val_loss: 1.0835 - val_acc: 0.6843\n",
      "Epoch 91/100\n",
      " - 15s - loss: 0.2734 - acc: 0.9180 - val_loss: 0.9493 - val_acc: 0.7128\n",
      "Epoch 92/100\n",
      " - 15s - loss: 0.1783 - acc: 0.9460 - val_loss: 0.9105 - val_acc: 0.7210\n",
      "Epoch 93/100\n",
      " - 15s - loss: 0.1663 - acc: 0.9440 - val_loss: 0.9844 - val_acc: 0.7149\n",
      "Epoch 94/100\n",
      " - 15s - loss: 0.2047 - acc: 0.9280 - val_loss: 0.9668 - val_acc: 0.7251\n",
      "Epoch 95/100\n",
      " - 15s - loss: 0.1844 - acc: 0.9340 - val_loss: 0.9768 - val_acc: 0.7088\n",
      "Epoch 96/100\n",
      " - 15s - loss: 0.1450 - acc: 0.9500 - val_loss: 0.8865 - val_acc: 0.7332\n",
      "Epoch 97/100\n",
      " - 15s - loss: 0.1843 - acc: 0.9320 - val_loss: 0.9858 - val_acc: 0.6986\n",
      "Epoch 98/100\n",
      " - 15s - loss: 0.2645 - acc: 0.9180 - val_loss: 0.9000 - val_acc: 0.7137\n",
      "Epoch 99/100\n",
      " - 15s - loss: 0.1514 - acc: 0.9520 - val_loss: 0.8990 - val_acc: 0.7210\n",
      "Epoch 100/100\n",
      " - 15s - loss: 0.1510 - acc: 0.9420 - val_loss: 1.0933 - val_acc: 0.6945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x246f8c9f860>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 使用 Adam optimizer，以較低的 learning rate 進行 fine-tuning\n",
    "model.compile(optimizer=Adam(lr=1e-5),\n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# 訓練模型\n",
    "#net_final.fit_generator(train_batches,\n",
    "                       # steps_per_epoch =50,\n",
    "                       # validation_data = valid_batches,\n",
    "                       # validation_steps = 50,\n",
    "                       # epochs = 10, verbose=2)\n",
    "\n",
    "model.fit_generator(train_batches, steps_per_epoch=50,epochs=100,validation_data=valid_batches, validation_steps=50, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('daisy', 0), ('dandelion', 1), ('rose', 2), ('sunflower', 3), ('tulip', 4)])\n"
     ]
    }
   ],
   "source": [
    "#同時儲存結構與權重，檔案的類別為HDF5\n",
    "from keras.models import load_model\n",
    "model.save('flower6.h5')\n",
    "print(train_batches.class_indices.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#載入HDF5檔案\n",
    "from keras.models import load_model\n",
    "# 載入模型\n",
    "classifier = load_model('flower6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (1) [0]\n",
      "0 (2) [0]\n",
      "0 (3) [0]\n",
      "1 (1) [0]\n",
      "1 (2) [0]\n",
      "1 (3) [0]\n",
      "2 (1) [0]\n",
      "2 (2) [0]\n",
      "2 (3) [0]\n",
      "3 (1) [0]\n",
      "3 (2) [0]\n",
      "3 (3) [0]\n",
      "4 (1) [0]\n",
      "4 (2) [0]\n",
      "4 (3) [0]\n"
     ]
    }
   ],
   "source": [
    "import sys,os,dlib,glob\n",
    "#from skimage import io\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "folder_path='exam2\\\\'\n",
    "# 列出指定路徑底下所有檔案(包含資料夾)\n",
    "allFileList = os.listdir(folder_path)\n",
    "# 逐一查詢檔案清單\n",
    "\n",
    "listlable = []  \n",
    "for file in allFileList:\n",
    "    f= folder_path+ file\n",
    "    file=os.path.splitext(file)[0]\n",
    "    #print(f)\n",
    "    \n",
    "    img = image.load_img(f, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "   \n",
    "    res=classifier.predict_classes(x) \n",
    "    print(file,res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasecience",
   "language": "python",
   "name": "datasecience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
